{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe4b3791-96e7-4ef3-9c2e-669bb6a2fa6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.3\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "print(pandas.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbd8ff9f-9369-497b-a11d-47fbe8d87c96",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (955020236.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[7], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    jupyter nbconvert --to python AdvancedVRP.ipynb\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ce19575-fde8-4cf3-80ac-49240a58dfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import time\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a37440cd-04b3-4257-8583-384db948cb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: matplotlib in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (4.55.8)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (2.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3157352c-0662-482c-90c9-a674a9eb5bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: osmnx in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (2.0.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (3.4.2)\n",
      "Requirement already satisfied: geopandas>=1.0 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from osmnx) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.22 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from osmnx) (2.2.2)\n",
      "Requirement already satisfied: pandas>=1.4 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from osmnx) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.27 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from osmnx) (2.32.3)\n",
      "Requirement already satisfied: shapely>=2.0 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from osmnx) (2.0.7)\n",
      "Requirement already satisfied: pyogrio>=0.7.2 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from geopandas>=1.0->osmnx) (0.10.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from geopandas>=1.0->osmnx) (24.2)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from geopandas>=1.0->osmnx) (3.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from pandas>=1.4->osmnx) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from pandas>=1.4->osmnx) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from pandas>=1.4->osmnx) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.27->osmnx) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.27->osmnx) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.27->osmnx) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.27->osmnx) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas>=1.4->osmnx) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install osmnx networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6739769-ad79-4832-854e-5be14ec473a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting streamlit\n",
      "  Downloading streamlit-1.42.2-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit)\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.0.0 (from streamlit)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<6,>=4.0 (from streamlit)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting click<9,>=7.0 (from streamlit)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from streamlit) (2.2.2)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from streamlit) (11.1.0)\n",
      "Collecting protobuf<6,>=3.20 (from streamlit)\n",
      "  Downloading protobuf-5.29.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting pyarrow>=7.0 (from streamlit)\n",
      "  Downloading pyarrow-19.0.1-cp313-cp313-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from streamlit) (2.32.3)\n",
      "Collecting rich<14,>=10.14.0 (from streamlit)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tenacity<10,>=8.1.0 (from streamlit)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typing-extensions<5,>=4.4.0 (from streamlit)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
      "  Downloading watchdog-6.0.0-py3-none-win_amd64.whl.metadata (44 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from altair<6,>=4.0->streamlit) (3.1.5)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit)\n",
      "  Downloading narwhals-1.28.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14,>=10.14.0->streamlit)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from rich<14,>=10.14.0->streamlit) (2.19.1)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Downloading streamlit-1.42.2-py2.py3-none-any.whl (9.6 MB)\n",
      "   ---------------------------------------- 0.0/9.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.6 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/9.6 MB 1.9 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.8/9.6 MB 1.8 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 1.3/9.6 MB 1.9 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 1.3/9.6 MB 1.9 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 1.6/9.6 MB 1.6 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 1.6/9.6 MB 1.6 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 1.8/9.6 MB 1.2 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 1.8/9.6 MB 1.2 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 2.4/9.6 MB 1.1 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 2.6/9.6 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 3.1/9.6 MB 1.3 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 3.7/9.6 MB 1.4 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 4.2/9.6 MB 1.5 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 4.5/9.6 MB 1.5 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 5.0/9.6 MB 1.5 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 5.2/9.6 MB 1.5 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 5.5/9.6 MB 1.5 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 5.8/9.6 MB 1.5 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 6.0/9.6 MB 1.5 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 6.3/9.6 MB 1.4 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 6.6/9.6 MB 1.5 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 6.8/9.6 MB 1.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 6.8/9.6 MB 1.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 7.1/9.6 MB 1.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 7.1/9.6 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 7.3/9.6 MB 1.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 7.9/9.6 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 8.4/9.6 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.9/9.6 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.4/9.6 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.6/9.6 MB 1.4 MB/s eta 0:00:00\n",
      "Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "   ---------------------------------------- 0.0/731.2 kB ? eta -:--:--\n",
      "   ---------------------------- ----------- 524.3/731.2 kB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 731.2/731.2 kB 3.4 MB/s eta 0:00:00\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Downloading protobuf-5.29.3-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Downloading pyarrow-19.0.1-cp313-cp313-win_amd64.whl (25.2 MB)\n",
      "   ---------------------------------------- 0.0/25.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/25.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.8/25.2 MB 3.0 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 1.6/25.2 MB 2.9 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 2.1/25.2 MB 2.9 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 2.6/25.2 MB 2.9 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 3.1/25.2 MB 3.0 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 3.7/25.2 MB 2.8 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 4.5/25.2 MB 2.8 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 5.0/25.2 MB 2.8 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 5.8/25.2 MB 2.8 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 6.3/25.2 MB 2.9 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 6.8/25.2 MB 2.8 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 7.3/25.2 MB 2.8 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 7.9/25.2 MB 2.8 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 8.4/25.2 MB 2.7 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 9.2/25.2 MB 2.7 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 9.7/25.2 MB 2.8 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 10.2/25.2 MB 2.7 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 10.5/25.2 MB 2.7 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 11.0/25.2 MB 2.7 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 11.8/25.2 MB 2.7 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 12.3/25.2 MB 2.7 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 12.8/25.2 MB 2.7 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 13.4/25.2 MB 2.7 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 13.6/25.2 MB 2.7 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 14.4/25.2 MB 2.6 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 14.9/25.2 MB 2.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 15.2/25.2 MB 2.6 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 15.7/25.2 MB 2.6 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 16.3/25.2 MB 2.6 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 16.5/25.2 MB 2.5 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 17.0/25.2 MB 2.5 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 17.6/25.2 MB 2.5 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 18.1/25.2 MB 2.5 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 18.4/25.2 MB 2.5 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 18.9/25.2 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 19.4/25.2 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 19.7/25.2 MB 2.5 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 20.4/25.2 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.7/25.2 MB 2.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 21.2/25.2 MB 2.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 21.8/25.2 MB 2.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 22.3/25.2 MB 2.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 22.8/25.2 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 23.1/25.2 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.9/25.2 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.4/25.2 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.2/25.2 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.2/25.2 MB 2.4 MB/s eta 0:00:00\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "   ---------------------------------------- 0.0/6.9 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.5/6.9 MB 3.8 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.3/6.9 MB 4.1 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.6/6.9 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.1/6.9 MB 2.6 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 2.6/6.9 MB 2.7 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 2.9/6.9 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 3.4/6.9 MB 2.3 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 3.9/6.9 MB 2.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 4.7/6.9 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 5.2/6.9 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 6.0/6.9 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.8/6.9 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.9/6.9 MB 2.6 MB/s eta 0:00:00\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading watchdog-6.0.0-py3-none-win_amd64.whl (79 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading narwhals-1.28.0-py3-none-any.whl (308 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: watchdog, typing-extensions, toml, tenacity, smmap, pyarrow, protobuf, narwhals, mdurl, click, cachetools, blinker, pydeck, markdown-it-py, gitdb, rich, gitpython, altair, streamlit\n",
      "Successfully installed altair-5.5.0 blinker-1.9.0 cachetools-5.5.2 click-8.1.8 gitdb-4.0.12 gitpython-3.1.44 markdown-it-py-3.0.0 mdurl-0.1.2 narwhals-1.28.0 protobuf-5.29.3 pyarrow-19.0.1 pydeck-0.9.1 rich-13.9.4 smmap-5.0.2 streamlit-1.42.2 tenacity-9.0.0 toml-0.10.2 typing-extensions-4.12.2 watchdog-6.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dddd720d-55f3-43fa-a569-f2020e41e466",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# Install required libraries\n",
    "!pip install osmnx geopy scipy matplotlib --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7140083-9026-4a69-b080-0847c6ab15c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ortools\n",
      "  Downloading ortools-9.12.4544-cp313-cp313-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting absl-py>=2.0.0 (from ortools)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from ortools) (2.2.2)\n",
      "Requirement already satisfied: pandas>=2.0.0 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from ortools) (2.2.3)\n",
      "Requirement already satisfied: protobuf<5.30,>=5.29.3 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from ortools) (5.29.3)\n",
      "Collecting immutabledict>=3.0.0 (from ortools)\n",
      "  Downloading immutabledict-4.2.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from pandas>=2.0.0->ortools) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from pandas>=2.0.0->ortools) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from pandas>=2.0.0->ortools) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->ortools) (1.17.0)\n",
      "Downloading ortools-9.12.4544-cp313-cp313-win_amd64.whl (18.1 MB)\n",
      "   ---------------------------------------- 0.0/18.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.8/18.1 MB 3.7 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 1.6/18.1 MB 3.9 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 2.1/18.1 MB 3.6 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 2.9/18.1 MB 3.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 3.7/18.1 MB 3.6 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 4.2/18.1 MB 3.5 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 4.5/18.1 MB 3.3 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 5.2/18.1 MB 3.2 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 5.8/18.1 MB 3.1 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 6.0/18.1 MB 3.0 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 6.6/18.1 MB 2.8 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 7.1/18.1 MB 2.8 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 7.6/18.1 MB 2.8 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 8.4/18.1 MB 2.8 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 8.7/18.1 MB 2.8 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 9.2/18.1 MB 2.8 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 9.7/18.1 MB 2.7 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 10.2/18.1 MB 2.7 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 10.7/18.1 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 11.5/18.1 MB 2.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 12.1/18.1 MB 2.7 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 12.6/18.1 MB 2.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 13.1/18.1 MB 2.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 13.9/18.1 MB 2.7 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 14.4/18.1 MB 2.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 15.2/18.1 MB 2.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 15.7/18.1 MB 2.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 16.3/18.1 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 16.8/18.1 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 17.0/18.1 MB 2.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 17.6/18.1 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  18.1/18.1 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.1/18.1 MB 2.6 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading immutabledict-4.2.1-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: immutabledict, absl-py, ortools\n",
      "Successfully installed absl-py-2.1.0 immutabledict-4.2.1 ortools-9.12.4544\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install ortools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0bcbf5f-44cd-41a6-ad35-3b388c5e1dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: folium in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (0.19.4)\n",
      "Requirement already satisfied: branca>=0.6.0 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from folium) (0.8.1)\n",
      "Requirement already satisfied: jinja2>=2.9 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from folium) (3.1.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from folium) (2.2.2)\n",
      "Requirement already satisfied: requests in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from folium) (2.32.3)\n",
      "Requirement already satisfied: xyzservices in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from folium) (2025.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from jinja2>=2.9->folium) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from requests->folium) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from requests->folium) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from requests->folium) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from requests->folium) (2025.1.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abuza\\appdata\\roaming\\python\\python313\\site-packages (from requests) (2025.1.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install folium\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c71c8992-4607-482f-83cb-b8e4f6cc9d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "API_KEY = \"M4gbWbXRcVHKsmy42AesQzR2rlrUarfm\"  # Replace with your actual API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44254405-a987-4ab5-b274-814d49e5af22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This application is used to convert notebook files (*.ipynb)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] WARNING | pattern 'AdvancedVRP.ipynb' matched no files\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        to various other formats.\n",
      "\n",
      "        WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
      "\n",
      "Options\n",
      "=======\n",
      "The options below are convenience aliases to configurable class-options,\n",
      "as listed in the \"Equivalent to\" description-line of the aliases.\n",
      "To see all configurable class-options for some <cmd>, use:\n",
      "    <cmd> --help-all\n",
      "\n",
      "--debug\n",
      "    set log level to logging.DEBUG (maximize logging output)\n",
      "    Equivalent to: [--Application.log_level=10]\n",
      "--show-config\n",
      "    Show the application's configuration (human-readable format)\n",
      "    Equivalent to: [--Application.show_config=True]\n",
      "--show-config-json\n",
      "    Show the application's configuration (json format)\n",
      "    Equivalent to: [--Application.show_config_json=True]\n",
      "--generate-config\n",
      "    generate default config file\n",
      "    Equivalent to: [--JupyterApp.generate_config=True]\n",
      "-y\n",
      "    Answer yes to any questions instead of prompting.\n",
      "    Equivalent to: [--JupyterApp.answer_yes=True]\n",
      "--execute\n",
      "    Execute the notebook prior to export.\n",
      "    Equivalent to: [--ExecutePreprocessor.enabled=True]\n",
      "--allow-errors\n",
      "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n",
      "    Equivalent to: [--ExecutePreprocessor.allow_errors=True]\n",
      "--stdin\n",
      "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n",
      "    Equivalent to: [--NbConvertApp.from_stdin=True]\n",
      "--stdout\n",
      "    Write notebook output to stdout instead of files.\n",
      "    Equivalent to: [--NbConvertApp.writer_class=StdoutWriter]\n",
      "--inplace\n",
      "    Run nbconvert in place, overwriting the existing notebook (only\n",
      "            relevant when converting to notebook format)\n",
      "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory=]\n",
      "--clear-output\n",
      "    Clear output of current file and save in place,\n",
      "            overwriting the existing notebook.\n",
      "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --ClearOutputPreprocessor.enabled=True]\n",
      "--coalesce-streams\n",
      "    Coalesce consecutive stdout and stderr outputs into one stream (within each cell).\n",
      "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --CoalesceStreamsPreprocessor.enabled=True]\n",
      "--no-prompt\n",
      "    Exclude input and output prompts from converted document.\n",
      "    Equivalent to: [--TemplateExporter.exclude_input_prompt=True --TemplateExporter.exclude_output_prompt=True]\n",
      "--no-input\n",
      "    Exclude input cells and output prompts from converted document.\n",
      "            This mode is ideal for generating code-free reports.\n",
      "    Equivalent to: [--TemplateExporter.exclude_output_prompt=True --TemplateExporter.exclude_input=True --TemplateExporter.exclude_input_prompt=True]\n",
      "--allow-chromium-download\n",
      "    Whether to allow downloading chromium if no suitable version is found on the system.\n",
      "    Equivalent to: [--WebPDFExporter.allow_chromium_download=True]\n",
      "--disable-chromium-sandbox\n",
      "    Disable chromium security sandbox when converting to PDF..\n",
      "    Equivalent to: [--WebPDFExporter.disable_sandbox=True]\n",
      "--show-input\n",
      "    Shows code input. This flag is only useful for dejavu users.\n",
      "    Equivalent to: [--TemplateExporter.exclude_input=False]\n",
      "--embed-images\n",
      "    Embed the images as base64 dataurls in the output. This flag is only useful for the HTML/WebPDF/Slides exports.\n",
      "    Equivalent to: [--HTMLExporter.embed_images=True]\n",
      "--sanitize-html\n",
      "    Whether the HTML in Markdown cells and cell outputs should be sanitized..\n",
      "    Equivalent to: [--HTMLExporter.sanitize_html=True]\n",
      "--log-level=<Enum>\n",
      "    Set the log level by value or name.\n",
      "    Choices: any of [0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL']\n",
      "    Default: 30\n",
      "    Equivalent to: [--Application.log_level]\n",
      "--config=<Unicode>\n",
      "    Full path of a config file.\n",
      "    Default: ''\n",
      "    Equivalent to: [--JupyterApp.config_file]\n",
      "--to=<Unicode>\n",
      "    The export format to be used, either one of the built-in formats\n",
      "            ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf']\n",
      "            or a dotted object name that represents the import path for an\n",
      "            ``Exporter`` class\n",
      "    Default: ''\n",
      "    Equivalent to: [--NbConvertApp.export_format]\n",
      "--template=<Unicode>\n",
      "    Name of the template to use\n",
      "    Default: ''\n",
      "    Equivalent to: [--TemplateExporter.template_name]\n",
      "--template-file=<Unicode>\n",
      "    Name of the template file to use\n",
      "    Default: None\n",
      "    Equivalent to: [--TemplateExporter.template_file]\n",
      "--theme=<Unicode>\n",
      "    Template specific theme(e.g. the name of a JupyterLab CSS theme distributed\n",
      "    as prebuilt extension for the lab template)\n",
      "    Default: 'light'\n",
      "    Equivalent to: [--HTMLExporter.theme]\n",
      "--sanitize_html=<Bool>\n",
      "    Whether the HTML in Markdown cells and cell outputs should be sanitized.This\n",
      "    should be set to True by nbviewer or similar tools.\n",
      "    Default: False\n",
      "    Equivalent to: [--HTMLExporter.sanitize_html]\n",
      "--writer=<DottedObjectName>\n",
      "    Writer class used to write the\n",
      "                                        results of the conversion\n",
      "    Default: 'FilesWriter'\n",
      "    Equivalent to: [--NbConvertApp.writer_class]\n",
      "--post=<DottedOrNone>\n",
      "    PostProcessor class used to write the\n",
      "                                        results of the conversion\n",
      "    Default: ''\n",
      "    Equivalent to: [--NbConvertApp.postprocessor_class]\n",
      "--output=<Unicode>\n",
      "    Overwrite base name use for output files.\n",
      "                Supports pattern replacements '{notebook_name}'.\n",
      "    Default: '{notebook_name}'\n",
      "    Equivalent to: [--NbConvertApp.output_base]\n",
      "--output-dir=<Unicode>\n",
      "    Directory to write output(s) to. Defaults\n",
      "                                  to output to the directory of each notebook. To recover\n",
      "                                  previous default behaviour (outputting to the current\n",
      "                                  working directory) use . as the flag value.\n",
      "    Default: ''\n",
      "    Equivalent to: [--FilesWriter.build_directory]\n",
      "--reveal-prefix=<Unicode>\n",
      "    The URL prefix for reveal.js (version 3.x).\n",
      "            This defaults to the reveal CDN, but can be any url pointing to a copy\n",
      "            of reveal.js.\n",
      "            For speaker notes to work, this must be a relative path to a local\n",
      "            copy of reveal.js: e.g., \"reveal.js\".\n",
      "            If a relative path is given, it must be a subdirectory of the\n",
      "            current directory (from which the server is run).\n",
      "            See the usage documentation\n",
      "            (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-slideshow)\n",
      "            for more details.\n",
      "    Default: ''\n",
      "    Equivalent to: [--SlidesExporter.reveal_url_prefix]\n",
      "--nbformat=<Enum>\n",
      "    The nbformat version to write.\n",
      "            Use this to downgrade notebooks.\n",
      "    Choices: any of [1, 2, 3, 4]\n",
      "    Default: 4\n",
      "    Equivalent to: [--NotebookExporter.nbformat_version]\n",
      "\n",
      "Examples\n",
      "--------\n",
      "\n",
      "    The simplest way to use nbconvert is\n",
      "\n",
      "            > jupyter nbconvert mynotebook.ipynb --to html\n",
      "\n",
      "            Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf'].\n",
      "\n",
      "            > jupyter nbconvert --to latex mynotebook.ipynb\n",
      "\n",
      "            Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
      "            'base', 'article' and 'report'.  HTML includes 'basic', 'lab' and\n",
      "            'classic'. You can specify the flavor of the format used.\n",
      "\n",
      "            > jupyter nbconvert --to html --template lab mynotebook.ipynb\n",
      "\n",
      "            You can also pipe the output to stdout, rather than a file\n",
      "\n",
      "            > jupyter nbconvert mynotebook.ipynb --stdout\n",
      "\n",
      "            PDF is generated via latex\n",
      "\n",
      "            > jupyter nbconvert mynotebook.ipynb --to pdf\n",
      "\n",
      "            You can get (and serve) a Reveal.js-powered slideshow\n",
      "\n",
      "            > jupyter nbconvert myslides.ipynb --to slides --post serve\n",
      "\n",
      "            Multiple notebooks can be given at the command line in a couple of\n",
      "            different ways:\n",
      "\n",
      "            > jupyter nbconvert notebook*.ipynb\n",
      "            > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n",
      "\n",
      "            or you can specify the notebooks list in a config file, containing::\n",
      "\n",
      "                c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
      "\n",
      "            > jupyter nbconvert --config mycfg.py\n",
      "\n",
      "To see all available configurables, use `--help-all`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to python AdvancedVRP.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5825571e-fd25-4eb7-9a7e-38bd2c686b99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading OSM data for 'Dubai, United Arab Emirates' (this may take time)...\n",
      "OSMnx graph download completed.\n",
      "✅ Warehouse 1, Jabal Ali, Dubai, UAE => Lat: 25.0338168, Lon: 55.1366041\n",
      "⚠️ Using fallback for Warehouse 2, Al Awir, Dubai, UAE: Lat 25.1555, Lon 55.5045\n",
      "⚠️ Using fallback for Fulfillment Center 1, Mudon, Dubai, UAE: Lat 25.0529, Lon 55.2774\n",
      "⚠️ Using fallback for Fulfillment Center 2, Al Manara, Dubai, UAE: Lat 25.1412, Lon 55.2148\n",
      "⚠️ Using fallback for Fulfillment Center 3, Al Garhoud, Dubai, UAE: Lat 25.2432, Lon 55.3487\n",
      "⚠️ Using fallback for Fulfillment Center 4, Warsan 1, Dubai, UAE: Lat 25.1614, Lon 55.4184\n",
      "✅ Arabian Ranches 2, Dubai, UAE => Lat: 25.034834699999998, Lon: 55.271921917095476\n",
      "✅ Remraam, Dubai, UAE => Lat: 25.00136485, Lon: 55.24886049659429\n",
      "✅ DAMAC Hills, Dubai, UAE => Lat: 25.0264384, Lon: 55.251228\n",
      "✅ Dubai Studio City, Dubai, UAE => Lat: 25.0415641, Lon: 55.2522587\n",
      "✅ Motor City, Dubai, UAE => Lat: 25.047690199999998, Lon: 55.23820948643042\n",
      "✅ Jumeirah Beach, Dubai, UAE => Lat: 25.185005949999997, Lon: 55.2234920068955\n",
      "✅ Umm Suqeim, Dubai, UAE => Lat: 25.1375268, Lon: 55.1957658\n",
      "✅ Al Safa, Dubai, UAE => Lat: 25.15563, Lon: 55.2285156\n",
      "✅ Al Wasl, Dubai, UAE => Lat: 25.1959326, Lon: 55.2557371\n",
      "✅ Al Barsha, Dubai, UAE => Lat: 25.096326, Lon: 55.1984022\n",
      "✅ Port Saeed, Dubai, UAE => Lat: 25.2604609, Lon: 55.3296278\n",
      "✅ Umm Ramool, Dubai, UAE => Lat: 25.2310318, Lon: 55.3674888\n",
      "✅ Nad Al Hamar, Dubai, UAE => Lat: 25.214114988514496, Lon: 55.37667162031641\n",
      "✅ Mirdif, Dubai, UAE => Lat: 25.2211708, Lon: 55.4224204\n",
      "✅ Al Rashidiya, Dubai, UAE => Lat: 25.222025, Lon: 55.3910064\n",
      "✅ International City, Dubai, UAE => Lat: 25.174163, Lon: 55.412478\n",
      "✅ Academic City, Dubai, UAE => Lat: 25.11241205, Lon: 55.409999268745516\n",
      "✅ Nad Al Sheba, Dubai, UAE => Lat: 25.1565887, Lon: 55.3500747\n",
      "✅ Al Warqa, Dubai, UAE => Lat: 25.19029595, Lon: 55.429248781359654\n",
      "✅ Dubai Silicon Oasis, Dubai, UAE => Lat: 25.12057915, Lon: 55.38865529646179\n",
      "✅ TomTom traffic for 26 coords.\n",
      "✅ Graph updated with TomTom speeds for edges.\n",
      "Driver 1 => route_indices = [2, 6, 7, 2, 2]\n",
      "Driver 2 => route_indices = [3, 9, 8, 3, 3]\n",
      "Driver 3 => route_indices = [4, 11, 10, 4, 4]\n",
      "Driver 4 => route_indices = [5, 13, 12, 5, 5]\n",
      "Driver 5 => route_indices = [2, 15, 14, 2, 2]\n",
      "Driver 6 => route_indices = [3, 17, 16, 3, 3]\n",
      "Driver 7 => route_indices = [4, 18, 19, 4, 4]\n",
      "Driver 8 => route_indices = [5, 21, 20, 5, 5]\n",
      "Driver 9 => route_indices = [2, 22, 23, 2, 2]\n",
      "Driver 10 => route_indices = [3, 24, 25, 3, 3]\n",
      "✅ Final expanded VRP map => ExpandedDubai_VRP.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "import folium\n",
    "import itertools\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "from folium.plugins import MarkerCluster, Search, AntPath\n",
    "from folium.features import CustomIcon, DivIcon\n",
    "from shapely.geometry import LineString\n",
    "from networkx.algorithms import approximation as approx\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "########################################\n",
    "# 0) Fallbacks (if needed)\n",
    "########################################\n",
    "geo_fallbacks = {\n",
    "    \"Warehouse 1, Jabal Ali, Dubai, UAE\": (24.9837, 55.0673),\n",
    "    \"Warehouse 2, Al Awir, Dubai, UAE\": (25.1555, 55.5045),\n",
    "    \"Fulfillment Center 1, Mudon, Dubai, UAE\": (25.0529, 55.2774),\n",
    "    \"Fulfillment Center 2, Al Manara, Dubai, UAE\": (25.1412, 55.2148),\n",
    "    \"Fulfillment Center 3, Al Garhoud, Dubai, UAE\": (25.2432, 55.3487),\n",
    "    \"Fulfillment Center 4, Warsan 1, Dubai, UAE\": (25.1614, 55.4184),\n",
    "}\n",
    "\n",
    "########################################\n",
    "# 1) Setup & Geocoding\n",
    "########################################\n",
    "geolocator = Nominatim(user_agent=\"route_optimization_app\")\n",
    "\n",
    "def geocode_locations(locations_list):\n",
    "    geolocations = []\n",
    "    for loc in locations_list:\n",
    "        try:\n",
    "            result = geolocator.geocode(loc, timeout=5)\n",
    "            if result:\n",
    "                geolocations.append((result.latitude, result.longitude))\n",
    "                print(f\"✅ {loc} => Lat: {result.latitude}, Lon: {result.longitude}\")\n",
    "            else:\n",
    "                if loc in geo_fallbacks:\n",
    "                    lat, lon = geo_fallbacks[loc]\n",
    "                    geolocations.append((lat, lon))\n",
    "                    print(f\"⚠️ Using fallback for {loc}: Lat {lat}, Lon {lon}\")\n",
    "                else:\n",
    "                    print(f\"❌ {loc} => No geocoding results. (Consider adding a fallback)\")\n",
    "                    geolocations.append(None)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error geocoding {loc}: {e}\")\n",
    "            geolocations.append(None)\n",
    "        time.sleep(0.1)\n",
    "    return geolocations\n",
    "\n",
    "########################################\n",
    "# 2) TomTom Real-Time Traffic\n",
    "########################################\n",
    "def fetch_tomtom_traffic(coordinates, tomtom_api_key):\n",
    "    base_url = \"https://api.tomtom.com/traffic/services/4/flowSegmentData/absolute/10/json\"\n",
    "    live_speeds = {}\n",
    "    for (lat, lon) in coordinates:\n",
    "        params = {\"point\": f\"{lat},{lon}\", \"unit\": \"KMPH\", \"key\": tomtom_api_key}\n",
    "        try:\n",
    "            r = requests.get(base_url, params=params)\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            if \"flowSegmentData\" in data:\n",
    "                seg = data[\"flowSegmentData\"]\n",
    "                speed = seg.get(\"currentSpeed\", 1)\n",
    "                live_speeds[(lat, lon)] = speed\n",
    "            else:\n",
    "                live_speeds[(lat, lon)] = 1\n",
    "        except:\n",
    "            live_speeds[(lat, lon)] = 1\n",
    "    print(f\"✅ TomTom traffic for {len(live_speeds)} coords.\")\n",
    "    return live_speeds\n",
    "\n",
    "########################################\n",
    "# 3) Prepare Warehouses, FCs, and Delivery Points\n",
    "########################################\n",
    "all_locations = [\n",
    "    \"Warehouse 1, Jabal Ali, Dubai, UAE\",\n",
    "    \"Warehouse 2, Al Awir, Dubai, UAE\",\n",
    "    \"Fulfillment Center 1, Mudon, Dubai, UAE\",\n",
    "    \"Fulfillment Center 2, Al Manara, Dubai, UAE\",\n",
    "    \"Fulfillment Center 3, Al Garhoud, Dubai, UAE\",\n",
    "    \"Fulfillment Center 4, Warsan 1, Dubai, UAE\",\n",
    "    \"Arabian Ranches 2, Dubai, UAE\",\n",
    "    \"Remraam, Dubai, UAE\",\n",
    "    \"DAMAC Hills, Dubai, UAE\",\n",
    "    \"Dubai Studio City, Dubai, UAE\",\n",
    "    \"Motor City, Dubai, UAE\",\n",
    "    \"Jumeirah Beach, Dubai, UAE\",\n",
    "    \"Umm Suqeim, Dubai, UAE\",\n",
    "    \"Al Safa, Dubai, UAE\",\n",
    "    \"Al Wasl, Dubai, UAE\",\n",
    "    \"Al Barsha, Dubai, UAE\",\n",
    "    \"Port Saeed, Dubai, UAE\",\n",
    "    \"Umm Ramool, Dubai, UAE\",\n",
    "    \"Nad Al Hamar, Dubai, UAE\",\n",
    "    \"Mirdif, Dubai, UAE\",\n",
    "    \"Al Rashidiya, Dubai, UAE\",\n",
    "    \"International City, Dubai, UAE\",\n",
    "    \"Academic City, Dubai, UAE\",\n",
    "    \"Nad Al Sheba, Dubai, UAE\",\n",
    "    \"Al Warqa, Dubai, UAE\",\n",
    "    \"Dubai Silicon Oasis, Dubai, UAE\",\n",
    "]\n",
    "\n",
    "time_priority_info = {}\n",
    "for idx, loc in enumerate(all_locations):\n",
    "    if idx < 2:\n",
    "        time_priority_info[loc] = {\"priority\": None, \"time_window\": None}\n",
    "    elif idx < 6:\n",
    "        time_priority_info[loc] = {\"priority\": None, \"time_window\": None}\n",
    "    else:\n",
    "        pr = random.randint(1, 3)\n",
    "        start_t = random.randint(8, 12)\n",
    "        end_t = start_t + random.randint(2, 4)\n",
    "        time_priority_info[loc] = {\"priority\": pr, \"time_window\": (start_t, end_t)}\n",
    "\n",
    "########################################\n",
    "# 4) Build OSMnx Graph for Dubai\n",
    "########################################\n",
    "print(\"Downloading OSM data for 'Dubai, United Arab Emirates' (this may take time)...\")\n",
    "graph = ox.graph_from_place(\"Dubai, United Arab Emirates\", network_type=\"drive\")\n",
    "print(\"OSMnx graph download completed.\")\n",
    "\n",
    "########################################\n",
    "# 5) Fuel & Emission Calculation\n",
    "########################################\n",
    "def calculate_fuel_and_emissions(distance_km, fuel_efficiency=12.0, fuel_price=3.0, emission_factor=0.2):\n",
    "    fuel_cost = (distance_km / fuel_efficiency) * fuel_price\n",
    "    co2_emission = distance_km * emission_factor\n",
    "    return fuel_cost, co2_emission\n",
    "\n",
    "########################################\n",
    "# 6) Update Graph with TomTom\n",
    "########################################\n",
    "def update_graph_with_tomtom(graph, speeds):\n",
    "    for u, v, key, data in graph.edges(keys=True, data=True):\n",
    "        if 'geometry' in data and isinstance(data['geometry'], LineString):\n",
    "            lat, lon = data['geometry'].coords[0]\n",
    "        else:\n",
    "            lat, lon = None, None\n",
    "        if (lat, lon) in speeds:\n",
    "            try:\n",
    "                speed_kmh = speeds[(lat, lon)]\n",
    "                if speed_kmh > 0:\n",
    "                    travel_time_hr = data[\"length\"] / (speed_kmh * 1000/3600)\n",
    "                    data[\"travel_time\"] = travel_time_hr * 1.2\n",
    "                else:\n",
    "                    data[\"travel_time\"] = float(\"inf\")\n",
    "            except:\n",
    "                pass\n",
    "    print(\"✅ Graph updated with TomTom speeds for edges.\")\n",
    "    return graph\n",
    "\n",
    "########################################\n",
    "# 7) Basic VRP Approach (Clustering + TSP)\n",
    "########################################\n",
    "drivers = [\n",
    "    {\"id\": 1, \"capacity\": 2, \"color\": \"red\"},\n",
    "    {\"id\": 2, \"capacity\": 2, \"color\": \"blue\"},\n",
    "    {\"id\": 3, \"capacity\": 2, \"color\": \"green\"},\n",
    "    {\"id\": 4, \"capacity\": 2, \"color\": \"purple\"},\n",
    "    {\"id\": 5, \"capacity\": 2, \"color\": \"orange\"},\n",
    "    {\"id\": 6, \"capacity\": 2, \"color\": \"darkred\"},\n",
    "    {\"id\": 7, \"capacity\": 2, \"color\": \"darkblue\"},\n",
    "    {\"id\": 8, \"capacity\": 2, \"color\": \"darkgreen\"},\n",
    "    {\"id\": 9, \"capacity\": 2, \"color\": \"cadetblue\"},\n",
    "    {\"id\": 10, \"capacity\": 2, \"color\": \"black\"},\n",
    "]\n",
    "\n",
    "def cluster_deliveries(indices, k=10):\n",
    "    chunk_size = max(1, len(indices)//k)\n",
    "    clusters = []\n",
    "    current = []\n",
    "    for idx in indices:\n",
    "        current.append(idx)\n",
    "        if len(current) >= chunk_size:\n",
    "            clusters.append(current)\n",
    "            current = []\n",
    "    if current:\n",
    "        clusters.append(current)\n",
    "    while len(clusters) > k:\n",
    "        clusters[-2].extend(clusters[-1])\n",
    "        clusters.pop()\n",
    "    return clusters\n",
    "\n",
    "def run_cluster_tsp(graph, sub_idxs, node_map):\n",
    "    \"\"\"\n",
    "    Build a cost matrix among sub_idxs and run TSP approximation.\n",
    "    The cost includes time + partial fuel + partial CO2 + priority penalty.\n",
    "    \"\"\"\n",
    "    cost = {}\n",
    "    for i, j in itertools.permutations(sub_idxs, 2):\n",
    "        try:\n",
    "            base_time = nx.shortest_path_length(graph, node_map[i], node_map[j], weight=\"travel_time\")\n",
    "            dist_m = nx.shortest_path_length(graph, node_map[i], node_map[j], weight=\"length\")\n",
    "            dist_km = dist_m / 1000.0\n",
    "            fuel_cost, co2_emission = calculate_fuel_and_emissions(dist_km)\n",
    "            loc_j = all_locations[j]\n",
    "            prj = time_priority_info[loc_j][\"priority\"]\n",
    "            final_cost = base_time + fuel_cost + (co2_emission * 0.5)\n",
    "            if prj is not None:\n",
    "                final_cost += (prj - 1) * 5\n",
    "            cost[(i, j)] = final_cost\n",
    "        except:\n",
    "            cost[(i, j)] = 999999\n",
    "    import math\n",
    "    subgraph = nx.complete_graph(len(sub_idxs))\n",
    "    for (u, v) in subgraph.edges():\n",
    "        real_u = sub_idxs[u]\n",
    "        real_v = sub_idxs[v]\n",
    "        subgraph[u][v][\"weight\"] = cost.get((real_u, real_v), math.inf)\n",
    "        subgraph[v][u][\"weight\"] = cost.get((real_v, real_u), math.inf)\n",
    "    route = approx.greedy_tsp(subgraph, weight=\"weight\")\n",
    "    if len(route) > 1:\n",
    "        # close the route by returning to start\n",
    "        route.append(route[0])\n",
    "    global_route = [sub_idxs[n] for n in route]\n",
    "    return global_route\n",
    "\n",
    "def solve_vrp_clustering(graph, node_list):\n",
    "    drop_indices = list(range(6, 26))\n",
    "    clusters = cluster_deliveries(drop_indices, k=len(drivers))\n",
    "    route_assignments = []\n",
    "    fc_list = [2, 3, 4, 5]\n",
    "    for i, cluster in enumerate(clusters):\n",
    "        fc_idx = fc_list[i % len(fc_list)]\n",
    "        sub_idxs = [fc_idx] + cluster\n",
    "        route = run_cluster_tsp(graph, sub_idxs, node_map=node_list)\n",
    "        route_assignments.append({\"driver\": drivers[i], \"route\": route})\n",
    "    return route_assignments\n",
    "\n",
    "def count_signals(path_nodes, G):\n",
    "    s = 0\n",
    "    for n in path_nodes:\n",
    "        if G.nodes[n].get(\"highway\") == \"traffic_signals\":\n",
    "            s += 1\n",
    "    return s\n",
    "\n",
    "########################################\n",
    "# 8) Baseline Calculation Using FC's\n",
    "########################################\n",
    "def calculate_naive_baseline(geocoded, node_list, G):\n",
    "    \"\"\"\n",
    "    For each delivery (indices 6..25), compute a round-trip from the nearest Fulfillment Center \n",
    "    (indices 2,3,4,5) instead of from Warehouse 1.\n",
    "    \"\"\"\n",
    "    fc_indices = [2, 3, 4, 5]\n",
    "    total_distance_km = 0.0\n",
    "    total_fuel_cost = 0.0\n",
    "    total_co2 = 0.0\n",
    "    for drop_idx in range(6, 26):\n",
    "        best_roundtrip = None\n",
    "        for fc_idx in fc_indices:\n",
    "            try:\n",
    "                out_path = nx.shortest_path(G, node_list[fc_idx], node_list[drop_idx], weight=\"length\")\n",
    "                ret_path = nx.shortest_path(G, node_list[drop_idx], node_list[fc_idx], weight=\"length\")\n",
    "                dist_m_out = sum(G.get_edge_data(out_path[i], out_path[i+1], 0).get(\"length\", 0) for i in range(len(out_path)-1))\n",
    "                dist_m_ret = sum(G.get_edge_data(ret_path[i], ret_path[i+1], 0).get(\"length\", 0) for i in range(len(ret_path)-1))\n",
    "                roundtrip_km = (dist_m_out + dist_m_ret) / 1000.0\n",
    "                if best_roundtrip is None or roundtrip_km < best_roundtrip:\n",
    "                    best_roundtrip = roundtrip_km\n",
    "            except nx.NetworkXNoPath:\n",
    "                continue\n",
    "        if best_roundtrip is not None:\n",
    "            total_distance_km += best_roundtrip\n",
    "            f_cost, co2_e = calculate_fuel_and_emissions(best_roundtrip)\n",
    "            total_fuel_cost += f_cost\n",
    "            total_co2 += co2_e\n",
    "    return total_distance_km, total_fuel_cost, total_co2\n",
    "\n",
    "########################################\n",
    "# 9) run_vrp() for direct usage\n",
    "########################################\n",
    "def run_vrp():\n",
    "    # 1) Geocode\n",
    "    geocoded = geocode_locations(all_locations)\n",
    "    coords = [r for r in geocoded if r is not None]\n",
    "    if not coords:\n",
    "        print(\"No valid coordinates found!\")\n",
    "        return (0, 0, 0)\n",
    "    \n",
    "    # 2) Fetch TomTom Speeds\n",
    "    TOMTOM_API_KEY = \"M4gbWbXRcVHKsmy42AesQzR2rlrUarfm\"\n",
    "    traffic_speeds = fetch_tomtom_traffic(coords, TOMTOM_API_KEY)\n",
    "    \n",
    "    # 3) Update Graph\n",
    "    g_updated = update_graph_with_tomtom(graph, traffic_speeds)\n",
    "    \n",
    "    # 4) Map each location to nearest node\n",
    "    valid_geocoded = [c for c in geocoded if c is not None]\n",
    "    if not valid_geocoded:\n",
    "        print(\"No valid geocoded locations found!\")\n",
    "        return (0, 0, 0)\n",
    "    \n",
    "    node_list = ox.distance.nearest_nodes(\n",
    "        g_updated,\n",
    "        [c[1] for c in valid_geocoded],\n",
    "        [c[0] for c in valid_geocoded]\n",
    "    )\n",
    "    \n",
    "    # 5) Calculate baseline\n",
    "    baseline_dist, baseline_fuel, baseline_co2 = calculate_naive_baseline(geocoded, node_list, g_updated)\n",
    "    \n",
    "    # 6) Solve VRP\n",
    "    route_assignments = solve_vrp_clustering(g_updated, node_list)\n",
    "    \n",
    "    # 7) Build Folium Map\n",
    "    m = folium.Map(tiles=\"CartoDB Positron\", zoom_start=10)\n",
    "    m.fit_bounds([(c[0], c[1]) for c in coords])\n",
    "    \n",
    "    markers_fg = folium.FeatureGroup(\"Markers\").add_to(m)\n",
    "    vrp_fg = folium.FeatureGroup(\"Multi-Driver VRP\").add_to(m)\n",
    "    \n",
    "    def create_warehouse_divicon(wh_name):\n",
    "        return DivIcon(\n",
    "            icon_size=(50,50),\n",
    "            icon_anchor=(25,50),\n",
    "            html=f\"\"\"\n",
    "            <div style=\"text-align:center;\">\n",
    "                <div style=\"font-size:24px;\">🏭</div>\n",
    "                <div style=\"font-size:12px; color:darkblue; margin-top:-3px;\">\n",
    "                    {wh_name}\n",
    "                </div>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "        )\n",
    "    \n",
    "    def create_fc_divicon(fc_label):\n",
    "        return DivIcon(\n",
    "            icon_size=(50,50),\n",
    "            icon_anchor=(25,50),\n",
    "            html=f\"\"\"\n",
    "            <div style=\"text-align:center;\">\n",
    "                <div style=\"font-size:24px;\">📦</div>\n",
    "                <div style=\"font-size:12px; color:darkgreen; margin-top:-3px;\">\n",
    "                    {fc_label}\n",
    "                </div>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "        )\n",
    "    \n",
    "    def create_delivery_pin_icon():\n",
    "        return DivIcon(\n",
    "            icon_size=(24,24),\n",
    "            icon_anchor=(12,24),\n",
    "            html=\"\"\"\n",
    "            <div style=\"font-size:24px; text-align:center;\">\n",
    "                📍\n",
    "            </div>\n",
    "            \"\"\"\n",
    "        )\n",
    "    \n",
    "    fc_conn_text = {\n",
    "        2: \"Connected with: Fulfillment Center (FC2) & Fulfillment Center (FC4)\",\n",
    "        3: \"Connected with: Fulfillment Center (FC1) & Fulfillment Center (FC3)\",\n",
    "        4: \"Connected with: Fulfillment Center (FC2) & Fulfillment Center (FC4)\",\n",
    "        5: \"Connected with: Fulfillment Center (FC3) & Fulfillment Center (FC1)\"\n",
    "    }\n",
    "    \n",
    "    # Marker loop\n",
    "    delivery_counter = 1\n",
    "    for idx, (loc, gc) in enumerate(zip(all_locations, geocoded)):\n",
    "        if not gc:\n",
    "            continue\n",
    "        lat, lon = gc\n",
    "        if idx < 2:\n",
    "            wh_label = f\"Warehouse {idx+1}\"\n",
    "            if idx == 0:\n",
    "                catering = \"Catering to: Fulfillment Center (FC1) & Fulfillment Center (FC2)\"\n",
    "            else:\n",
    "                catering = \"Catering to: Fulfillment Center (FC3) & Fulfillment Center (FC4)\"\n",
    "            popup_text = f\"<b>{loc}</b><br/>Lat: {lat:.5f}, Lon: {lon:.5f}<br/>{catering}\"\n",
    "            folium.Marker(\n",
    "                location=(lat, lon),\n",
    "                tooltip=wh_label,\n",
    "                popup=popup_text,\n",
    "                icon=create_warehouse_divicon(wh_label)\n",
    "            ).add_to(markers_fg)\n",
    "        elif idx < 6:\n",
    "            fc_num = idx - 1\n",
    "            fc_label = f\"Fulfillment Center (FC{fc_num})\"\n",
    "            conn_text = fc_conn_text.get(idx, \"\")\n",
    "            popup_text = f\"<b>{loc}</b><br/>Lat: {lat:.5f}, Lon: {lon:.5f}<br/>{conn_text}\"\n",
    "            folium.Marker(\n",
    "                location=(lat, lon),\n",
    "                tooltip=fc_label,\n",
    "                popup=popup_text,\n",
    "                icon=create_fc_divicon(fc_label)\n",
    "            ).add_to(markers_fg)\n",
    "        else:\n",
    "            pr = time_priority_info[loc][\"priority\"]\n",
    "            tooltip_text = f\"Delivery Point {delivery_counter}\"\n",
    "            popup_text = (\n",
    "                f\"<b>{loc}</b><br/>Delivery Point {delivery_counter}\"\n",
    "                f\"<br/>Lat: {lat:.5f}, Lon: {lon:.5f}\"\n",
    "                f\"<br/>Priority: {pr if pr else 'N/A'}\"\n",
    "            )\n",
    "            folium.Marker(\n",
    "                location=(lat, lon),\n",
    "                tooltip=tooltip_text,\n",
    "                popup=popup_text,\n",
    "                icon=create_delivery_pin_icon()\n",
    "            ).add_to(markers_fg)\n",
    "            delivery_counter += 1\n",
    "    \n",
    "    # FC-FC lines\n",
    "    fc_pairs = [(2,3), (3,4), (4,5), (5,2)]\n",
    "    for (f1, f2) in fc_pairs:\n",
    "        latlon1 = geocoded[f1]\n",
    "        latlon2 = geocoded[f2]\n",
    "        if latlon1 and latlon2:\n",
    "            folium.PolyLine(\n",
    "                locations=[latlon1, latlon2],\n",
    "                color=\"darkcyan\",\n",
    "                weight=3,\n",
    "                dash_array=\"5,5\",\n",
    "                tooltip=f\"FC-FC Link: {all_locations[f1]} ↔ {all_locations[f2]}\"\n",
    "            ).add_to(vrp_fg)\n",
    "    \n",
    "    # Warehouse-FC lines\n",
    "    warehouse_fc_connections = [(0,2), (0,3), (1,4), (1,5)]\n",
    "    for (wh_idx, fc_idx) in warehouse_fc_connections:\n",
    "        latlon_wh = geocoded[wh_idx]\n",
    "        latlon_fc = geocoded[fc_idx]\n",
    "        if latlon_wh and latlon_fc:\n",
    "            folium.PolyLine(\n",
    "                locations=[latlon_wh, latlon_fc],\n",
    "                color=\"teal\",\n",
    "                weight=3,\n",
    "                dash_array=\"3,6\",\n",
    "                tooltip=f\"{all_locations[wh_idx]} ↔ {all_locations[fc_idx]}\"\n",
    "            ).add_to(vrp_fg)\n",
    "    \n",
    "    # Keep track of global totals (including final leg) for distance/fuel/CO2\n",
    "    total_map_distance = 0.0\n",
    "    total_map_fuel_cost = 0.0\n",
    "    total_map_co2_emission = 0.0\n",
    "\n",
    "    # For computing the \"average delivery time\" that excludes final leg\n",
    "    sum_of_times_excl_final = 0.0\n",
    "    num_drivers_excl = 0\n",
    "\n",
    "    base_speed = 40.0\n",
    "    \n",
    "    # Plot each driver's route and compute metrics\n",
    "    for rinfo in route_assignments:\n",
    "        driver = rinfo[\"driver\"]\n",
    "        route_indices = rinfo[\"route\"]\n",
    "        if len(route_indices) < 2:\n",
    "            print(f\"Driver {driver['id']}: route too short => {route_indices}\")\n",
    "            continue\n",
    "        \n",
    "        # 1) Full-route distance/time (for total env metrics)\n",
    "        driver_dist_m_full = 0.0\n",
    "        path_nodes_full = []\n",
    "        for i in range(len(route_indices) - 1):\n",
    "            s_i = route_indices[i]\n",
    "            e_i = route_indices[i+1]\n",
    "            if nx.has_path(g_updated, node_list[s_i], node_list[e_i]):\n",
    "                sub_path = nx.shortest_path(g_updated, node_list[s_i], node_list[e_i], weight=\"length\")\n",
    "                for sp_i in range(len(sub_path) - 1):\n",
    "                    edge_data = g_updated.get_edge_data(sub_path[sp_i], sub_path[sp_i+1], 0)\n",
    "                    if edge_data:\n",
    "                        driver_dist_m_full += edge_data.get(\"length\", 0)\n",
    "                path_nodes_full.extend(sub_path)\n",
    "\n",
    "        driver_dist_km_full = driver_dist_m_full / 1000.0\n",
    "        fuel_full, co2_full = calculate_fuel_and_emissions(driver_dist_km_full)\n",
    "        # signals\n",
    "        sigs_full = count_signals(path_nodes_full, g_updated)\n",
    "        base_time_min_full = (driver_dist_km_full / base_speed) * 60\n",
    "        total_time_min_full = round(base_time_min_full + (sigs_full * 0.5), 2)\n",
    "\n",
    "        # Add these to global totals (full route)\n",
    "        total_map_distance += driver_dist_km_full\n",
    "        total_map_fuel_cost += fuel_full\n",
    "        total_map_co2_emission += co2_full\n",
    "\n",
    "        # 2) Exclude the final leg for \"average time\"\n",
    "        # This partial route covers only i in range(len(route_indices) - 2)\n",
    "        # so we skip the last leg\n",
    "        if len(route_indices) > 2:  # if there's at least 2 legs\n",
    "            partial_dist_m = 0.0\n",
    "            partial_nodes = []\n",
    "            for i in range(len(route_indices) - 2):  \n",
    "                s_i = route_indices[i]\n",
    "                e_i = route_indices[i+1]\n",
    "                if nx.has_path(g_updated, node_list[s_i], node_list[e_i]):\n",
    "                    sub_path = nx.shortest_path(g_updated, node_list[s_i], node_list[e_i], weight=\"length\")\n",
    "                    for sp_i in range(len(sub_path) - 1):\n",
    "                        edge_data = g_updated.get_edge_data(sub_path[sp_i], sub_path[sp_i+1], 0)\n",
    "                        if edge_data:\n",
    "                            partial_dist_m += edge_data.get(\"length\", 0)\n",
    "                    partial_nodes.extend(sub_path)\n",
    "\n",
    "            partial_dist_km = partial_dist_m / 1000.0\n",
    "            partial_sigs = count_signals(partial_nodes, g_updated)\n",
    "            partial_time_min_base = (partial_dist_km / base_speed) * 60\n",
    "            partial_time_min = round(partial_time_min_base + (partial_sigs * 0.5), 2)\n",
    "\n",
    "            # Add to sum_of_times_excl_final\n",
    "            sum_of_times_excl_final += partial_time_min\n",
    "            num_drivers_excl += 1\n",
    "        else:\n",
    "            # if there's only 1 leg, there's no \"final leg\" to exclude\n",
    "            # so we skip or treat partial time as zero\n",
    "            sum_of_times_excl_final += 0\n",
    "            num_drivers_excl += 1\n",
    "\n",
    "        # 3) Plot each leg (including final leg) for the map\n",
    "        print(f\"Driver {driver['id']} => route_indices = {route_indices}\")\n",
    "        for i in range(len(route_indices) - 1):\n",
    "            s_i = route_indices[i]\n",
    "            e_i = route_indices[i+1]\n",
    "\n",
    "            # If final iteration => label \"Back to FC\"\n",
    "            if i == len(route_indices) - 2:\n",
    "                leg_str = \"Back to FC\"\n",
    "            else:\n",
    "                leg_str = f\"Leg {i+1}\"\n",
    "\n",
    "            leg_path_nodes = []\n",
    "            leg_dist_m = 0.0\n",
    "            if nx.has_path(g_updated, node_list[s_i], node_list[e_i]):\n",
    "                sub_path = nx.shortest_path(g_updated, node_list[s_i], node_list[e_i], weight=\"length\")\n",
    "                for sp_i in range(len(sub_path) - 1):\n",
    "                    edge_data = g_updated.get_edge_data(sub_path[sp_i], sub_path[sp_i+1], 0)\n",
    "                    if edge_data:\n",
    "                        leg_dist_m += edge_data.get(\"length\", 0)\n",
    "                leg_path_nodes = sub_path\n",
    "\n",
    "            if not leg_path_nodes:\n",
    "                continue\n",
    "\n",
    "            coords_path = [(g_updated.nodes[n][\"y\"], g_updated.nodes[n][\"x\"]) for n in leg_path_nodes]\n",
    "            if not coords_path:\n",
    "                continue\n",
    "\n",
    "            leg_dist_km = round(leg_dist_m / 1000.0, 2)\n",
    "            leg_signals = count_signals(leg_path_nodes, g_updated)\n",
    "            leg_time_min = round((leg_dist_km / base_speed) * 60 + (leg_signals * 0.5), 2)\n",
    "\n",
    "            leg_tooltip = (\n",
    "                f\"<b>Driver {driver['id']}, {leg_str}</b><br/>\"\n",
    "                f\"Leg Distance: {leg_dist_km} km<br/>\"\n",
    "                f\"Leg Time: {leg_time_min} min<br/>\"\n",
    "                f\"Total Trip: {round(driver_dist_km_full,2)} km, {total_time_min_full} min\"\n",
    "            )\n",
    "\n",
    "            AntPath(\n",
    "                locations=coords_path,\n",
    "                dash_array=[10, 20],\n",
    "                delay=600,\n",
    "                color=driver[\"color\"],\n",
    "                weight=4,\n",
    "                tooltip=leg_tooltip\n",
    "            ).add_to(vrp_fg)\n",
    "    \n",
    "    folium.LayerControl().add_to(m)\n",
    "    \n",
    "    # We'll compute the \"average delivery time\" only from partial routes\n",
    "    # that skip the final leg\n",
    "    if num_drivers_excl > 0:\n",
    "        avg_delivery_time_excl = round(sum_of_times_excl_final / num_drivers_excl, 2)\n",
    "    else:\n",
    "        avg_delivery_time_excl = 0.0\n",
    "    \n",
    "    # Show search bar\n",
    "    search = Search(\n",
    "        layer=markers_fg,\n",
    "        search_label='tooltip',\n",
    "        placeholder='Search...',\n",
    "        collapsed=False\n",
    "    )\n",
    "    search.add_to(m)\n",
    "    \n",
    "    # Legend\n",
    "    legend_html = '''\n",
    "    <div style=\"position: fixed; bottom: 30px; left: 30px; width: 220px;\n",
    "         background-color: rgba(255, 255, 255, 0.9);\n",
    "         z-index:9999; border:2px solid #444; border-radius:5px; padding:10px;\n",
    "         font-size:12px;\">\n",
    "      <h4 style=\"margin-top:0;\">Legend</h4>\n",
    "      <b>Driver Routes</b><br/>\n",
    "      <span style=\"color:red;\">■</span> D1 &nbsp;\n",
    "      <span style=\"color:blue;\">■</span> D2 &nbsp;\n",
    "      <span style=\"color:green;\">■</span> D3 &nbsp;\n",
    "      <span style=\"color:purple;\">■</span> D4 <br/>\n",
    "      <span style=\"color:orange;\">■</span> D5 &nbsp;\n",
    "      <span style=\"color:darkred;\">■</span> D6 &nbsp;\n",
    "      <span style=\"color:darkblue;\">■</span> D7 &nbsp;\n",
    "      <span style=\"color:darkgreen;\">■</span> D8 <br/>\n",
    "      <span style=\"color:cadetblue;\">■</span> D9 &nbsp;\n",
    "      <span style=\"color:black;\">■</span> D10 <br/>\n",
    "      <hr style=\"margin:5px 0;\">\n",
    "      <b>Icons</b><br/>\n",
    "      🏭 Warehouses<br/>\n",
    "      📦 Fulfillment Centers<br/>\n",
    "      📍 Delivery Points<br/>\n",
    "      <hr style=\"margin:5px 0;\">\n",
    "      <small>FC-FC: darkcyan dotted lines<br/>\n",
    "      WH-FC: teal dashed lines</small>\n",
    "    </div>\n",
    "    '''\n",
    "    m.get_root().html.add_child(folium.Element(legend_html))\n",
    "    \n",
    "    # Sustainability & partial avg time\n",
    "    co2_saved = round(baseline_co2 - total_map_co2_emission, 2)\n",
    "    fuel_saved = round(baseline_fuel - total_map_fuel_cost, 2)\n",
    "    disclaimer_html = f'''\n",
    "    <div style=\"position: fixed; bottom: 30px; right: 30px; width: 320px;\n",
    "        background-color: rgba(255,255,255,0.9);\n",
    "        z-index:9999; border:2px solid #444; border-radius:5px; padding:10px;\n",
    "        font-size:12px; line-height:1.3em;\">\n",
    "      <b>Map Overview</b><br/>\n",
    "      * This map shows 2 Warehouses, 4 Fulfillment Centers, and 20 Delivery Points.<br/>\n",
    "      * Routes are optimized using a VRP + TSP approach with priority-based deliveries.<br/>\n",
    "      * Each driver handles 2 drops with total trip < 70 km.<br/>\n",
    "      * Final leg is excluded from the average delivery time below.<br/>\n",
    "      <hr>\n",
    "      <b>🌱 Sustainability Impact</b><br/>\n",
    "      ♻️ CO₂ Saved: {co2_saved} kg<br/>\n",
    "      ⛽ Fuel Cost Saved: AED {fuel_saved}<br/>\n",
    "      <hr>\n",
    "      <b>Avg Delivery Time (excl. final leg)</b><br/>\n",
    "      {avg_delivery_time_excl} min\n",
    "    </div>\n",
    "    '''\n",
    "    m.get_root().html.add_child(folium.Element(disclaimer_html))\n",
    "    \n",
    "    hover_js = \"\"\"\n",
    "    <script>\n",
    "        var elements = document.getElementsByClassName('leaflet-interactive');\n",
    "        for (var i=0; i<elements.length; i++){\n",
    "            elements[i].addEventListener('mouseover', function(event){\n",
    "                event.target.setAttribute('stroke-width','6');\n",
    "            });\n",
    "            elements[i].addEventListener('mouseout', function(event){\n",
    "                event.target.setAttribute('stroke-width','4');\n",
    "            });\n",
    "        }\n",
    "    </script>\n",
    "    \"\"\"\n",
    "    m.get_root().html.add_child(folium.Element(hover_js))\n",
    "    \n",
    "    m.save(\"ExpandedDubai_VRP.html\")\n",
    "    print(\"✅ Final expanded VRP map => ExpandedDubai_VRP.html\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_vrp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf167f4-25fa-4efd-ae7a-39672cc25f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
